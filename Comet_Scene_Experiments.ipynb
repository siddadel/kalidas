{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Comet-Scene-Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddadel/kalidas/blob/main/Comet_Scene_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu2EXmoATgdK",
        "outputId": "7dc1ea4c-dce7-4e41-ffc0-d79479259435"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install transformers --quiet\n",
        "!git clone https://github.com/allenai/comet-atomic-2020\n",
        "!pip install -r ./comet-atomic-2020/requirements.txt --quiet\n",
        "!wget https://storage.googleapis.com/ai2-mosaic-public/projects/mosaic-kgs/comet-atomic_2020_BART.zip\n",
        "!unzip comet-atomic_2020_BART.zip"
      ],
      "id": "Tu2EXmoATgdK",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.7 MB/s \n",
            "\u001b[?25hCloning into 'comet-atomic-2020'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 166 (delta 42), reused 84 (delta 27), pack-reused 56\u001b[K\n",
            "Receiving objects: 100% (166/166), 7.15 MiB | 37.37 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 313 kB 54.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 379 kB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 54.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 58.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 70.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 65.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 791 kB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 374 kB 47.3 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pympler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.23 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.5.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.30.0 which is incompatible.\u001b[0m\n",
            "--2021-11-30 09:20:22--  https://storage.googleapis.com/ai2-mosaic-public/projects/mosaic-kgs/comet-atomic_2020_BART.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.98.128, 74.125.31.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.98.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1507095346 (1.4G) [application/zip]\n",
            "Saving to: ‘comet-atomic_2020_BART.zip’\n",
            "\n",
            "comet-atomic_2020_B 100%[===================>]   1.40G   154MB/s    in 8.8s    \n",
            "\n",
            "2021-11-30 09:20:30 (163 MB/s) - ‘comet-atomic_2020_BART.zip’ saved [1507095346/1507095346]\n",
            "\n",
            "Archive:  comet-atomic_2020_BART.zip\n",
            "   creating: comet-atomic_2020_BART/\n",
            "  inflating: comet-atomic_2020_BART/added_tokens.json  \n",
            "  inflating: comet-atomic_2020_BART/.DS_Store  \n",
            "  inflating: __MACOSX/comet-atomic_2020_BART/._.DS_Store  \n",
            "  inflating: comet-atomic_2020_BART/tokenizer_config.json  \n",
            "  inflating: comet-atomic_2020_BART/special_tokens_map.json  \n",
            "  inflating: comet-atomic_2020_BART/config.json  \n",
            "  inflating: comet-atomic_2020_BART/.added_tokens.json.swp  \n",
            "  inflating: comet-atomic_2020_BART/merges.txt  \n",
            "  inflating: comet-atomic_2020_BART/pytorch_model.bin  \n",
            "  inflating: comet-atomic_2020_BART/vocab.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NtPCimL6vHH",
        "outputId": "d092d6c6-c765-407b-85cd-2d0b498dde76"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "2NtPCimL6vHH",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 30 09:20:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Seu4t-mgWJyN"
      },
      "source": [
        "data_root = \"/content/drive/MyDrive/ANLP21/scripts_txt\"\n",
        "#data_root = \"/content/drive/MyDrive/ANLP21/scripts_sample\"\n",
        "output_dir= \"/content/drive/MyDrive/ANLP21/exp\""
      ],
      "id": "Seu4t-mgWJyN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7133eb7"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from joblib import Parallel, delayed\n",
        "import pandas as pd\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "id": "f7133eb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU2IZ__dgPFn"
      },
      "source": [
        "def run(method):\n",
        "    results = []\n",
        "    files = os.listdir(data_root)\n",
        "    random.shuffle(files)\n",
        "    \n",
        "#     [method(filename, open(os.path.join(data_root, filename), 'r', encoding = \"utf-8\").read()) for filename in files]\n",
        "#     return results\n",
        "    # results = Parallel(n_jobs=2)(delayed(method)(filename, open(os.path.join(data_root, filename), 'r', encoding = \"utf-8\").read()) for filename in files)\n",
        "    results = [method(filename, open(os.path.join(data_root, filename), 'r', encoding = \"utf-8\").read()) for filename in files]\n",
        "    return results\n",
        "\n",
        "\n",
        "def sentence_tokens(doc):\n",
        "    return [sent.text for sent in doc.sents]\n",
        "    \n",
        "\n",
        "def uppercase(txt):\n",
        "#     https://stackoverflow.com/questions/4598315/regex-to-match-only-uppercase-words-with-some-exceptions\n",
        "    uppercases = set(re.findall(r\"\\b[A-Z][A-Z]+\\b\", txt))\n",
        "    return uppercases\n",
        "\n",
        "\n",
        "def get_scenes(txt):\n",
        "    scenes = re.split(\"INT.|EXT.|INT./EXT.\", txt)\n",
        "#     print(len(scenes))\n",
        "    return scenes\n",
        "\n",
        "def get_characters(doc):\n",
        "    return Counter([str(ent).strip().lower() for ent in filter(lambda e: e.label_== \"PERSON\", doc.ents)])\n",
        "    \n",
        "def get_data(txt):\n",
        "#     txt = txt.replace('\\t',\" \")\n",
        "#     txt = txt.replace('\\n',\" \")\n",
        "    scenes = get_scenes(txt)\n",
        "    doc = nlp(txt)\n",
        "    counts = get_characters(doc)\n",
        "    return (scenes, counts)\n",
        "  \n",
        "def get_primary_character(characters):\n",
        "    return str(characters.most_common()[0][0])"
      ],
      "id": "fU2IZ__dgPFn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ddc3c3"
      },
      "source": [
        "class Film:\n",
        "    def __init__(self, name, protagonist):\n",
        "        self.name = name\n",
        "        self.protagonist = protagonist\n",
        "        self.scenes = []\n",
        "    \n",
        "    def add(self, scene):\n",
        "        self.scenes.append(scene)\n",
        "        \n",
        "class Scene:\n",
        "    def __init__(self):\n",
        "        self.items = []\n",
        "        \n",
        "    def add(self, item):\n",
        "        self.items.append(item)\n",
        "        \n",
        "class SceneItem:\n",
        "    def __init__(self):\n",
        "        self.lines = []\n",
        "        \n",
        "    def add(self, line):\n",
        "        self.lines.append(line)\n",
        "        \n",
        "    def __str__(self):\n",
        "        return \" \".join(self.lines)\n",
        "    \n",
        "    def is_empty(self):\n",
        "        return len(self.lines)==0\n",
        "    \n",
        "class Dialogue(SceneItem):\n",
        "    \n",
        "    def __init__(self, character):\n",
        "        self.lines = []\n",
        "        self.character = character\n",
        "\n",
        "    \n",
        "    def __str__(self):\n",
        "        return self.character +\" says, \\\"\"+\" \".join(self.lines)+\"\\\"\""
      ],
      "id": "d4ddc3c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6694f614",
        "outputId": "9e76fb4b-8c7c-4305-8124-83a567295e4f"
      },
      "source": [
        "#scene processing can not be parallelized because of speaking flag\n",
        "def process_scene(scene_txt, characters, film):\n",
        "        scene = Scene()\n",
        "        film.add(scene)\n",
        "        lines = scene_txt.split(\"\\n\")\n",
        "        \n",
        "        starts_speaking = False\n",
        "        item = SceneItem()\n",
        "        for line in lines:\n",
        "            if(line.strip() == \"\"):\n",
        "                if(starts_speaking):\n",
        "                    starts_speaking = False\n",
        "                    #sometimes an uppercase line describes things and is not dialogue\n",
        "                    if(item.is_empty()):\n",
        "                        temp = item.character\n",
        "                        item = SceneItem()\n",
        "                        item.add(temp)\n",
        "                if(not item.is_empty()):\n",
        "                    scene.add(item)\n",
        "                item = SceneItem()\n",
        "            elif(line.strip().lower() in characters.keys() or line.strip().isupper()):\n",
        "                starts_speaking = True\n",
        "                item = Dialogue(line.strip())\n",
        "            else:\n",
        "                item.add(line.strip())\n",
        "\n",
        "def process_film(filename, txt):\n",
        "    print(filename, end=\", \")\n",
        "    scene_txts, characters = get_data(txt)\n",
        "    primary_character = get_primary_character(characters)\n",
        "    film = Film(filename, primary_character)\n",
        "    # [process_scene(scene_txt, characters, film) for scene_txt in scene_txts]\n",
        "    # Parallel(n_jobs=4)(delayed(process_scene)(scene_txt, characters, film) for scene_txt in scene_txts)\n",
        "    for scene_txt in scene_txts:\n",
        "        process_scene(scene_txt, characters, film)\n",
        "    return film\n",
        "\n",
        "results = run(process_film)"
      ],
      "id": "6694f614",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "snow_falling_on_cedars.txt, fear_and_loathing_in_las_vegas.txt, the_fisher_king.txt, curse_of_the_cat_people.txt, terminator.txt, ghost_ship.txt, blue_velvet.txt, u_turn.txt, 1492_conquest_of_paradise.txt, pirates_of_the_caribbean.txt, star_trek_07_generations.txt, devil_wears_prada_the.txt, on_the_waterfront.txt, kids.txt, basic.txt, alien.txt, fargo.txt, swingers.txt, gandhi.txt, peggy_sue_got_married.txt, rush_hour_2.txt, hannibal.txt, crime_spree.txt, clerks.txt, last_of_the_mohicans.txt, annie_hall.txt, being_there.txt, excalibur.txt, wild_at_heart.txt, midnight_cowboy.txt, meet_john_doe.txt, coco.txt, batman_2_unproduced.txt, one_saliva_bubble.txt, metro.txt, klute.txt, mash.txt, all_about_eve.txt, made_for_each_other.txt, boy_who_never_slept.txt, crash_1996.txt, drop_dead_gorgeous.txt, predator.txt, l.a._confidential.txt, ride_the_high_country.txt, true_believer.txt, pet_sematary.txt, the_night_of_the_hunter.txt, croupier.txt, independence_day.txt, blade_ii.txt, kafka.txt, lethal_weapon.txt, misery.txt, the_majestic.txt, bones.txt, badlands.txt, isle_of_the_dead.txt, bottle_rocket.txt, nightmare_on_elm_street_4_dream_master.txt, sense_and_sensibility.txt, made.txt, raising_arizona.txt, tall_in_the_saddle.txt, le_grand_bleu.txt, the_nightmare_before_christmas.txt, the_piano.txt, seven.txt, the_shipping_news.txt, very_bad_things.txt, jaws_2.txt, little_men.txt, conspiracy_theory.txt, the_pianist.txt, thunderheart.txt, rko_281.txt, mrs._brown.txt, basic_instinct.txt, the_cider_house_rules.txt, as_good_as_it_gets.txt, next_friday.txt, traffic.txt, reservoir_dogs.txt, double_indemnity.txt, airplane.txt, minority_report.txt, scream.txt, the_fabulous_baker_boys.txt, the_doors_of_perception.txt, beavis_and_butthead_do_america.txt, taxi_driver.txt, sweet_smell_of_success.txt, phone_booth.txt, unforgiven.txt, little_nicky.txt, the_day_the_clown_cried.txt, ghost.txt, brazil.txt, pearl_harbor.txt, dog_day_afternoon.txt, twin_peaks_fire_walk_with_me.txt, the_crowded_room.txt, the_xfiles_movie.txt, witness.txt, fatal_instinct.txt, body_of_evidence.txt, chinatown.txt, music_of_the_heart_fifty_violins.txt, dumb_and_dumber.txt, frequency.txt, the_shining.txt, american_graffiti.txt, eight_scenes_from_the_life_of_hank_williams.txt, detroit_rock_city.txt, jane_eyre.txt, silverado.txt, the_searchers.txt, playback.txt, mimic.txt, the_haunting_of_hill_house_the_haunting.txt, o_brother_where_art_thou.txt, almost_famous.txt, the_ghost_and_the_darkness.txt, slither.txt, warm_springs.txt, faceoff.txt, toy_story.txt, feast__revised_draft.txt, transformers_the_movie.txt, the_believer.txt, joker.txt, the_big_blue.txt, mystery_men.txt, wes_cravens_new_nightmare.txt, the_horse_wisperer.txt, eternal_sunshine_of_the_spotless_mind.txt, stone_my_heart.txt, hannah_and_her_sisters.txt, 15_minutes.txt, jay_and_silent_bob_strike_back.txt, indiana_jones_and_the_temple_of_doom.txt, lord_of_illusions.txt, austin_powers_2_the_spy_who_shagged_me.txt, sugar_and_spice.txt, no_country_for_old_men_shooting.txt, antz.txt, the_anniversary_party.txt, bodies_rest_and_motion.txt, scary_movie_2.txt, titanic.txt, man_in_the_iron_mask.txt, birthday_girl.txt, who_framed_roger_rabbit_who_shot_roger_rabbit.txt, the_thing.txt, house_of_1000_corpses.txt, the_doors.txt, lone_star.txt, station_west.txt, ronin.txt, affliction.txt, state_and_main.txt, platinum_blonde.txt, the_crying_game.txt, star_trek_02_the_wrath_of_khan.txt, rush_hour.txt, mr._deeds_goes_to_town.txt, airplane_ii_the_sequel.txt, smokin_aces.txt, bound.txt, batman.txt, the_corruptor.txt, the_man_who_wasnt_there.txt, top_gun.txt, erin_brockovich.txt, donnie_brasco.txt, insomnia.txt, cliffhanger.txt, the_relic.txt, a_hard_days_night.txt, mission_impossible.txt, the_cell.txt, serial_mom.txt, the_life_and_death_of_colonel_blimp.txt, deep_rising.txt, batman_returns.txt, roughshod.txt, rabid.txt, the_last_temptation_of_christ.txt, apocalypse_now_redux.txt, grosse_pointe_blank.txt, blue_hotel.txt, the_assignment.txt, when_a_stranger_calls.txt, logans_run.txt, the_hospital.txt, barton_fink.txt, sleepy_hollow.txt, resident_evil__romero__unproduced.txt, looking_for_the_man.txt, the_village_originally_the_woods.txt, signs.txt, the_birds.txt, domino.txt, memento.txt, the_grapes_of_wrath.txt, 13_days.txt, the_dragons_of_krull.txt, thor_ragnarok.txt, quills.txt, the_cooler.txt, life_as_a_house.txt, mission_impossible_ii.txt, the_french_connection.txt, cold_mountain.txt, four_rooms.txt, the_salton_sea.txt, bad_day_at_black_rock.txt, what_about_bob.txt, the_butterfly_effect.txt, code_of_silence.txt, feast__early_draft.txt, carnivore.txt, its_a_wonderful_life.txt, wall_street.txt, hard_rain.txt, copycat.txt, entrapment.txt, three_kings_spoils_of_war.txt, vertigo.txt, autumn_in_new_york.txt, the_insider.txt, wag_the_dog.txt, planet_of_the_apes.txt, american_pie.txt, halloween_6_the_curse_of_michael_myers_halloween_666_the_origin_of_michael_myers.txt, saving_private_ryan.txt, i_walked_with_a_zombie.txt, raiders_of_the_lost_ark_indiana_jones.txt, heathers.txt, i_am_sam.txt, happy_campers.txt, mr._blandings_builds_his_dream_house.txt, being_john_malkovich.txt, sphere.txt, the_apartment.txt, grand_hotel.txt, jerry_maguire.txt, a_prayer_before_dawn.txt, jackie_brown.txt, alien_nation.txt, the_patriot.txt, the_5th_element.txt, rebel_without_a_cause.txt, major_league.txt, dead_poets_society.txt, sex_lies_and_videotape.txt, schindlers_list.txt, 12_monkeys.txt, willow.txt, south_park_bigger_longer_uncut.txt, the_hustler.txt, even_cowgirls_get_the_blues.txt, black_rain.txt, blade_trinity.txt, thirteen_days.txt, marty.txt, hardcore.txt, season_of_the_witch_mean_streets.txt, lake_placid.txt, thelma_and_louise.txt, star_trek_08_first_contact.txt, heavy_metal.txt, the_body_snatcher.txt, batman_forever.txt, american_madness.txt, gods_and_monsters.txt, beetle_juice.txt, the_godfather.txt, fast_times_at_ridgemont_high.txt, friday_the_13th_part_8_jason_takes_manhatten.txt, gang_related.txt, unbreakable.txt, rocky.txt, hider_in_the_house.txt, hero.txt, leviathan.txt, jurassic_park_3.txt, election.txt, sgt._rock.txt, blood_simple.txt, moonstruck.txt, 8_mm.txt, starman.txt, the_ploughmans_lunch.txt, austin_powers_international_man_of_mystery.txt, you_can_count_on_me.txt, human_nature.txt, amadeus.txt, stagecoach.txt, the_bijou.txt, 84_charlie_mopic.txt, the_abyss.txt, the_public_eye.txt, ill_do_anything.txt, the_fantastic_four.txt, fifty_violins_filmed_as_music_of_the_heart.txt, friday_the_13th_part_10_jason_x.txt, sex_lies_and_videotapes.txt, the_prophecy.txt, the_graduate.txt, pet_sematary_ii.txt, wild_things.txt, the_seventh_victim.txt, from_dusk_till_dawn.txt, duck_soup.txt, intolerable_cruelty.txt, the_lost_weekend.txt, bringing_out_the_dead.txt, kundun.txt, airforce_one.txt, friday_the_13th.txt, nightmare_on_elm_street_6_freddys_dead_the_final_nightmare.txt, jfk.txt, apt_pupil.txt, jurassic_park.txt, tron.txt, hellboy.txt, the_lost_boys.txt, gattaca.txt, good_will_hunting.txt, love_and_basketball.txt, shakespeare_in_love.txt, american_beauty.txt, fletch.txt, barry_lyndon.txt, return_of_the_apes.txt, forrest_gump.txt, crow_3_resurrection.txt, the_shawshank_redemption.txt, wonder_boys.txt, beloved.txt, the_battle_of_algiers.txt, the_grifters.txt, living_in_oblivion.txt, the_silence_of_the_lambs.txt, malcolm_x.txt, bad_santa.txt, nightmare_on_elm_street_5_dream_child.txt, ed_wood.txt, the_crow_salvation.txt, nashville.txt, never_been_kissed.txt, braveheart.txt, his_girl_friday.txt, blow.txt, cinema_paradiso.txt, theres_something_about_mary.txt, antitrust.txt, the_haunting.txt, pulp_fiction.txt, the_talented_mr._ripley.txt, hellraiser.txt, the_cable_guy.txt, smokey_and_the_bandit.txt, men_in_black.txt, the_family_man.txt, shivers.txt, buffy_the_vampire_slayer.txt, big_sick_the.txt, freddy_vs._jason.txt, danish_girl_the.txt, aliens.txt, u_turn_stray_dogs.txt, frankenstein_1994.txt, so_i_married_an_axe_murderer.txt, high_fidelity.txt, the_cincinnati_kid.txt, mission_to_mars.txt, the_ladykillers.txt, the_american_president.txt, bachelor_party.txt, the_mummy_1999.txt, reindeer_games.txt, kate_and_leopold.txt, 3_kings_spoils_of_war.txt, xxx.txt, dark_angel__pilot.txt, what_lies_beneath.txt, fight_club.txt, life.txt, hellbound_hellraiser_ii.txt, the_adventures_of_ford_fairlane_ford_fairlane.txt, mr._smith_goes_to_washington.txt, one_flew_over_the_cuckoos_nest.txt, sideways.txt, the_day_the_earth_stood_still.txt, ford_fairlane_the_adventures_of_ford_fairlane.txt, thx_1138.txt, henry_fool.txt, harold_and_maude.txt, bedlam.txt, the_verdict.txt, stepmom.txt, ed_tv.txt, 8_millimeter.txt, kong_king_kong.txt, cruel_intentions.txt, the_boondock_saints.txt, panther.txt, taking_sides.txt, the_thin_man.txt, 2001_a_space_odyssey.txt, under_fire.txt, chasing_amy.txt, a_quiet_place.txt, the_truman_show.txt, gone_in_sixty_seconds.txt, stolen_summer.txt, monkeybone.txt, an_american_werewolf_in_paris.txt, to_sleep_with_anger.txt, raging_bull.txt, sling_blade.txt, mobsters.txt, bull_durham.txt, magnolia.txt, jaws.txt, shampoo.txt, kalifornia.txt, assassins.txt, ninotchka.txt, the_avengers.txt, 48_hours.txt, hostage.txt, the_godfather_part_2.txt, demolition_man.txt, light_sleeper.txt, hope_and_glory.txt, the_crow.txt, lost_horizon.txt, committed_filmed_as_crazy_love.txt, jurassic_park_2_the_lost_world.txt, naked_city.txt, an_american_werewolf_in_london.txt, casino.txt, big_fish.txt, citizen_kane.txt, millers_crossing.txt, officer_and_a_gentleman_an.txt, house_on_haunted_hill.txt, jennifer_eight.txt, the_limey.txt, psycho.txt, all_the_kings_men.txt, broadcast_news.txt, freddys_dead_the_final_nightmare.txt, white_christmas.txt, it.txt, soldier.txt, portrait_of_jennie.txt, apocalypse_now.txt, midnight_run.txt, blair_witch_ii.txt, the_usual_suspects.txt, king_kong_kong.txt, star_trek_10_nemesis.txt, lost_highway.txt, the_jackie_robinson_story.txt, the_sixth_sense.txt, blade.txt, the_blast_from_the_past.txt, the_big_lebowski.txt, below.txt, mean_streets_season_of_the_witch.txt, dark_city.txt, nightmare_on_elm_street_7_wes_cravens_new_nightmare.txt, event_horizon.txt, philadelphia.txt, blackkklansman.txt, glengarry_glen_ross.txt, peeping_tom.txt, the_sweet_hereafter.txt, simone.txt, american_psycho.txt, sunset_blvd..txt, halloween.txt, ghost_world.txt, the_haunting_the_haunting_of_hill_house.txt, nixon.txt, black_panther.txt, punch_drunk_love.txt, charade.txt, nurse_betty.txt, "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "775dde4b",
        "outputId": "e161b098-bbae-4a4c-a52d-5266c9e2737d"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1,r'./comet-atomic-2020/models/comet_atomic2020_bart')\n",
        "from generation_example import Comet\n",
        "print(\"model loading ...\")\n",
        "comet = Comet(\"comet-atomic_2020_BART\")\n",
        "comet.model.zero_grad()\n",
        "print(\"model loaded\")"
      ],
      "id": "775dde4b",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model loading ...\n",
            "model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qldX1Qs1Xsxp",
        "outputId": "e7523445-fe9d-4837-a603-4505dd2be8f1"
      },
      "source": [
        "data = []\n",
        "film_id = 0\n",
        "for film in results:\n",
        "    film_id += 1\n",
        "    scene_id = 0\n",
        "    for scene in film.scenes:\n",
        "        scene_id += 1\n",
        "        item_id = 0\n",
        "        for item in scene.items:\n",
        "            item_id += 1\n",
        "            character = None\n",
        "            if type(item) == Dialogue:\n",
        "                character = item.character\n",
        "            \n",
        "            data.append((film.name, scene_id, item_id, item, character, film.protagonist.upper()))\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data, columns=['film', 'scene', 'item_ids', 'item', 'character', 'protagonist'])\n",
        "df"
      ],
      "id": "qldX1Qs1Xsxp",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>film</th>\n",
              "      <th>scene</th>\n",
              "      <th>item_ids</th>\n",
              "      <th>item</th>\n",
              "      <th>character</th>\n",
              "      <th>protagonist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>You've Got Mail</td>\n",
              "      <td>None</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>by Nora Ephron &amp; Delia Ephron</td>\n",
              "      <td>None</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Based on:</td>\n",
              "      <td>None</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>The Shop Around The corner</td>\n",
              "      <td>None</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>by Nikolaus Laszlo</td>\n",
              "      <td>None</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905246</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>161</td>\n",
              "      <td>4</td>\n",
              "      <td>BETTY says, \"Could I get some service here, pl...</td>\n",
              "      <td>BETTY</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905247</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>161</td>\n",
              "      <td>5</td>\n",
              "      <td>Without looking, the waiter approaches, tops o...</td>\n",
              "      <td>None</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905248</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>161</td>\n",
              "      <td>6</td>\n",
              "      <td>POSTSCRIPT: says, \"Betty Sizemore appeared in ...</td>\n",
              "      <td>POSTSCRIPT:</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905249</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>161</td>\n",
              "      <td>7</td>\n",
              "      <td>FADE OUT:</td>\n",
              "      <td>None</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905250</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>161</td>\n",
              "      <td>8</td>\n",
              "      <td>THE END</td>\n",
              "      <td>None</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>905251 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      film  scene  ...    character protagonist\n",
              "0       youve_got_mail.txt      1  ...         None         JOE\n",
              "1       youve_got_mail.txt      1  ...         None         JOE\n",
              "2       youve_got_mail.txt      1  ...         None         JOE\n",
              "3       youve_got_mail.txt      1  ...         None         JOE\n",
              "4       youve_got_mail.txt      1  ...         None         JOE\n",
              "...                    ...    ...  ...          ...         ...\n",
              "905246     nurse_betty.txt    161  ...        BETTY       BETTY\n",
              "905247     nurse_betty.txt    161  ...         None       BETTY\n",
              "905248     nurse_betty.txt    161  ...  POSTSCRIPT:       BETTY\n",
              "905249     nurse_betty.txt    161  ...         None       BETTY\n",
              "905250     nurse_betty.txt    161  ...         None       BETTY\n",
              "\n",
              "[905251 rows x 6 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cb56cf59",
        "outputId": "8ecba7de-4eb9-470f-aad1-929fd49a1e06"
      },
      "source": [
        "df1 = df[~df['character'].isnull() & (df['character']==df['protagonist'])]\n",
        "df1"
      ],
      "id": "cb56cf59",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>film</th>\n",
              "      <th>scene</th>\n",
              "      <th>item_ids</th>\n",
              "      <th>item</th>\n",
              "      <th>character</th>\n",
              "      <th>protagonist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>JOE says, \"Mmmmmhmmm --\"</td>\n",
              "      <td>JOE</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>JOE says, \"Am I going?\"</td>\n",
              "      <td>JOE</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>JOE says, \"Can't I just give them money?  That...</td>\n",
              "      <td>JOE</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>JOE says, \"All right, I'll go.  You're late.\"</td>\n",
              "      <td>JOE</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>youve_got_mail.txt</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>JOE says, \"That sounds great.\"</td>\n",
              "      <td>JOE</td>\n",
              "      <td>JOE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905222</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>156</td>\n",
              "      <td>19</td>\n",
              "      <td>BETTY says, \"... it's too bad you're such an a...</td>\n",
              "      <td>BETTY</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905227</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>157</td>\n",
              "      <td>3</td>\n",
              "      <td>BETTY says, \"... there's always a chance, David.\"</td>\n",
              "      <td>BETTY</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905230</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>157</td>\n",
              "      <td>6</td>\n",
              "      <td>BETTY says, \"(whispering to him) Doctor, if yo...</td>\n",
              "      <td>BETTY</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905232</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>157</td>\n",
              "      <td>8</td>\n",
              "      <td>BETTY says, \"No, it's up to us.  I love you, D...</td>\n",
              "      <td>BETTY</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905246</th>\n",
              "      <td>nurse_betty.txt</td>\n",
              "      <td>161</td>\n",
              "      <td>4</td>\n",
              "      <td>BETTY says, \"Could I get some service here, pl...</td>\n",
              "      <td>BETTY</td>\n",
              "      <td>BETTY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>95915 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      film  scene  ...  character protagonist\n",
              "62      youve_got_mail.txt      8  ...        JOE         JOE\n",
              "65      youve_got_mail.txt      8  ...        JOE         JOE\n",
              "67      youve_got_mail.txt      8  ...        JOE         JOE\n",
              "69      youve_got_mail.txt      8  ...        JOE         JOE\n",
              "174     youve_got_mail.txt     23  ...        JOE         JOE\n",
              "...                    ...    ...  ...        ...         ...\n",
              "905222     nurse_betty.txt    156  ...      BETTY       BETTY\n",
              "905227     nurse_betty.txt    157  ...      BETTY       BETTY\n",
              "905230     nurse_betty.txt    157  ...      BETTY       BETTY\n",
              "905232     nurse_betty.txt    157  ...      BETTY       BETTY\n",
              "905246     nurse_betty.txt    161  ...      BETTY       BETTY\n",
              "\n",
              "[95915 rows x 6 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9653b97b",
        "scrolled": false
      },
      "source": [
        "relations = [\"CapableOf\",  \"Desires\",  \"MotivatedByGoal\",  \"xAttr\", \"xNeed\", \"xReact\", \"xReason\", \"xWant\"]\n",
        "\n",
        "vocabulary = set()\n",
        "\n",
        "film_bags = {}\n",
        "\n",
        "def register_in_bag(film, token, relation):\n",
        "    if film not in film_bags:\n",
        "      film_bags[film] = {}\n",
        "    if(relation not in film_bags[film]):\n",
        "      film_bags[film][relation] = set()\n",
        "    film_bags[film][relation].add(token)\n",
        "    vocabulary.add(token)\n",
        "    \n",
        "def process_results(film, results, relations):\n",
        "    for i in range(len(relations)):\n",
        "      relation = relations[i]\n",
        "      for result in results[i]:\n",
        "        tokens = result.split(' ')\n",
        "        for token in tokens:\n",
        "          if token not in nlp.Defaults.stop_words:\n",
        "            register_in_bag(film, token, relation)\n",
        "\n",
        "log = []\n",
        "def infer(film, item, relations):\n",
        "    queries= [\"{} {} [GEN]\".format(item, relation) for relation in relations]\n",
        "    results = comet.generate(queries, decode_method=\"beam\", num_generate=5)\n",
        "    if film not in log:\n",
        "      print(film, end=\",\")\n",
        "      log.append(film)\n",
        "    process_results(film, results, relations)"
      ],
      "id": "9653b97b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qe0h7046---_",
        "outputId": "e99dc8bb-c472-443c-ade3-c6e0ad087ade"
      },
      "source": [
        "df1[['film','item']].to_csv('data.csv')\n",
        "from google.colab import files\n",
        "files.download(\"data.csv\")"
      ],
      "id": "qe0h7046---_",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_405bbc3e-76ee-45b7-bf87-cb9fcc04e8e7\", \"data.csv\", 9962445)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "etNoZyuoJYlb",
        "outputId": "402d554c-a55f-4766-9c79-7cedb9269454"
      },
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/ANLP21/data.csv\")\n",
        "df1.groupby(['film']).count()"
      ],
      "id": "etNoZyuoJYlb",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>film</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10_things_i_hate_about_you.txt</th>\n",
              "      <td>218</td>\n",
              "      <td>218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_monkeys.txt</th>\n",
              "      <td>176</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_days.txt</th>\n",
              "      <td>183</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492_conquest_of_paradise.txt</th>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_minutes.txt</th>\n",
              "      <td>145</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wild_things.txt</th>\n",
              "      <td>144</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>willow.txt</th>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>witness.txt</th>\n",
              "      <td>146</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xxx.txt</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>youve_got_mail.txt</th>\n",
              "      <td>251</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>488 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Unnamed: 0  item\n",
              "film                                            \n",
              "10_things_i_hate_about_you.txt         218   218\n",
              "12_monkeys.txt                         176   176\n",
              "13_days.txt                            183   183\n",
              "1492_conquest_of_paradise.txt           19    19\n",
              "15_minutes.txt                         145   145\n",
              "...                                    ...   ...\n",
              "wild_things.txt                        144   144\n",
              "willow.txt                             229   229\n",
              "witness.txt                            146   146\n",
              "xxx.txt                                  7     7\n",
              "youve_got_mail.txt                     251   251\n",
              "\n",
              "[488 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EszpE5um_kXr",
        "outputId": "5c6874a0-43a4-4881-e604-1849d6124884"
      },
      "source": [
        "!pip install dask[dataframe] --upgrade \n",
        "import dask.dataframe as dd\n",
        "from dask.multiprocessing import get"
      ],
      "id": "EszpE5um_kXr",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.2)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n",
            "Installing collected packages: locket, partd, fsspec\n",
            "Successfully installed fsspec-2021.11.1 locket-0.2.1 partd-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHzsIqbcgCNc",
        "outputId": "2d03b6c1-b7ba-4fe0-da89-a8f67dab3eea"
      },
      "source": [
        "df1.apply(lambda row: infer(row['film'], row['item'], relations), axis=1)\n",
        "\n",
        "# data = df1[['film','item']]\n",
        "# ddata = dd.from_pandas(data, npartitions=30)\n",
        "\n",
        "# def myfunc(row): \n",
        "#   return infer(row['film'], row['item'], relations)\n",
        "\n",
        "\n",
        "# res = ddata.map_partitions(lambda df: df.apply((lambda row: myfunc(*row)), axis=1)).compute(get=get)  \n"
      ],
      "id": "jHzsIqbcgCNc",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "youve_got_mail.txt,the_hebrew_hammer.txt,the_cat_people.txt,backdraft.txt,trainspotting.txt,mighty_morphin_power_rangers.txt,the_english_patient.txt,pleasantville.txt,american_outlaws.txt,five_easy_pieces.txt,tremors.txt,the_woodsman.txt,crazy_love_was_committed.txt,the_game.txt,star_trek_01_the_motion_picture.txt,the_bourne_identity.txt,the_lord_of_the_rings_the_return_of_the_king.txt,the_time_machine.txt,pitch_black.txt,eight_millimeter.txt,the_african_queen.txt,mumford.txt,cast_away.txt,how_to_train_your_dragon.txt,stalag_17.txt,dragon_slayer.txt,the_princess_bride.txt,spiderman.txt,juno.txt,enemy_of_the_state.txt,it_happened_one_night.txt,platoon.txt,twelve_monkeys.txt,conquest_of_paradise_1492.txt,the_battle_of_shaker_heights.txt,new_nightmare.txt,el_mariachi.txt,some_like_it_hot.txt,deep_cover.txt,erik_the_viking.txt,a_nightmare_on_elm_street.txt,happy_birthday_wanda_june.txt,10_things_i_hate_about_you.txt,the_sting.txt,bruce_almighty.txt,ferris_buellers_day_off.txt,investigation.txt,snow_falling_on_cedars.txt,fear_and_loathing_in_las_vegas.txt,the_fisher_king.txt,curse_of_the_cat_people.txt,terminator.txt,ghost_ship.txt,blue_velvet.txt,u_turn.txt,1492_conquest_of_paradise.txt,star_trek_07_generations.txt,devil_wears_prada_the.txt,on_the_waterfront.txt,kids.txt,basic.txt,alien.txt,fargo.txt,swingers.txt,gandhi.txt,peggy_sue_got_married.txt,rush_hour_2.txt,hannibal.txt,crime_spree.txt,clerks.txt,last_of_the_mohicans.txt,being_there.txt,excalibur.txt,wild_at_heart.txt,midnight_cowboy.txt,meet_john_doe.txt,coco.txt,batman_2_unproduced.txt,one_saliva_bubble.txt,metro.txt,klute.txt,mash.txt,all_about_eve.txt,boy_who_never_slept.txt,crash_1996.txt,drop_dead_gorgeous.txt,predator.txt,l.a._confidential.txt,true_believer.txt,pet_sematary.txt,croupier.txt,independence_day.txt,blade_ii.txt,kafka.txt,lethal_weapon.txt,misery.txt,the_majestic.txt,bones.txt,badlands.txt,isle_of_the_dead.txt,bottle_rocket.txt,nightmare_on_elm_street_4_dream_master.txt,made.txt,le_grand_bleu.txt,the_nightmare_before_christmas.txt,the_piano.txt,the_shipping_news.txt,very_bad_things.txt,jaws_2.txt,little_men.txt,conspiracy_theory.txt,the_pianist.txt,thunderheart.txt,rko_281.txt,mrs._brown.txt,the_cider_house_rules.txt,as_good_as_it_gets.txt,"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mznwpPHKwtpA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "80115ea6-b808-4caa-9729-95fa635549d1"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "vocabulary = list(vocabulary)\n",
        "film_vectors = []\n",
        "for film in film_bags:\n",
        "  relation_bag = [] \n",
        "  for relation in film_bags[film]:\n",
        "    relation_bag.append([1 if word in film_bags[film][relation] else 0 for word in vocabulary])\n",
        "  film_vectors.append(relation_bag)\n",
        "            \n",
        "X = np.array(film_vectors)\n",
        "w, h, d = len(film_vectors), len(relations), len(vocabulary)"
      ],
      "id": "mznwpPHKwtpA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf5f7a3f414e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfilm_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilm_bags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocabulary' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StN3PPzq6y8I"
      },
      "source": [
        "def plot_3d(X, w, h, d):\n",
        "  assert X.shape == (w, h, d)\n",
        "  X = X.reshape((w,h*d))\n",
        "\n",
        "  tsne_model = TSNE(perplexity=40, n_components=3, init='pca', n_iter=2500, random_state=23)\n",
        "  new_values = tsne_model.fit_transform(X)\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "  z = []\n",
        "  for value in new_values:\n",
        "      x.append(value[0])\n",
        "      y.append(value[1])\n",
        "      z.append(value[2])\n",
        "          \n",
        "  plt.figure(figsize=(16, 16)) \n",
        "  ax = plt.axes(projection='3d')\n",
        "  ax.scatter3D(x, y, z, cmap='viridis')\n",
        "\n",
        "\n",
        "def plot_2d(X, w, h, d):\n",
        "  assert X.shape == (w, h, d)\n",
        "  X = X.reshape((w,h*d))\n",
        "  tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
        "  new_values = tsne_model.fit_transform(X)\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "  for value in new_values:\n",
        "      x.append(value[0])\n",
        "      y.append(value[1])\n",
        "          \n",
        "  plt.figure(figsize=(16, 16)) \n",
        "  plt.scatter(x,y, cmap='viridis')\n",
        "  plt.show()"
      ],
      "id": "StN3PPzq6y8I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9_VkWEdPDdc"
      },
      "source": [
        "plot_3d(X, w, h, d)"
      ],
      "id": "Q9_VkWEdPDdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pczVSoJ2Utxw"
      },
      "source": [
        "plot_2d(X, w, h, d)"
      ],
      "id": "pczVSoJ2Utxw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjmkEi5hLf_X"
      },
      "source": [
        ""
      ],
      "id": "pjmkEi5hLf_X",
      "execution_count": null,
      "outputs": []
    }
  ]
}