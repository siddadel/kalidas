{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPEpamW5c3yWqw4n3f7u6IG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddadel/kalidas/blob/main/Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmMVmlrKkgra",
        "outputId": "bf314f17-2e3e-40a5-ebb5-878e2978b99b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  4 17:48:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9-qC9ClklW8",
        "outputId": "68abc42b-0e1b-4fbb-ab9a-80dcafd3cdc8"
      },
      "source": [
        "!pip install transformers --quiet\n",
        "!git clone https://github.com/allenai/comet-atomic-2020\n",
        "!pip install -r ./comet-atomic-2020/requirements.txt --quiet\n",
        "!wget https://storage.googleapis.com/ai2-mosaic-public/projects/mosaic-kgs/comet-atomic_2020_BART.zip\n",
        "!unzip comet-atomic_2020_BART.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 607 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 60.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 79.9 MB/s \n",
            "\u001b[?25hCloning into 'comet-atomic-2020'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 184 (delta 56), reused 90 (delta 32), pack-reused 56\u001b[K\n",
            "Receiving objects: 100% (184/184), 7.16 MiB | 6.28 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 313 kB 38.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 379 kB 60.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 73.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 62.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 77.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 78.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 126 kB 89.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 791 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 374 kB 96.5 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pympler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.23 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.6.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.30.1 which is incompatible.\u001b[0m\n",
            "--2021-12-04 17:48:33--  https://storage.googleapis.com/ai2-mosaic-public/projects/mosaic-kgs/comet-atomic_2020_BART.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.157.128, 74.125.204.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.157.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1507095346 (1.4G) [application/zip]\n",
            "Saving to: ‘comet-atomic_2020_BART.zip’\n",
            "\n",
            "comet-atomic_2020_B 100%[===================>]   1.40G  36.9MB/s    in 36s     \n",
            "\n",
            "2021-12-04 17:49:09 (40.1 MB/s) - ‘comet-atomic_2020_BART.zip’ saved [1507095346/1507095346]\n",
            "\n",
            "Archive:  comet-atomic_2020_BART.zip\n",
            "   creating: comet-atomic_2020_BART/\n",
            "  inflating: comet-atomic_2020_BART/added_tokens.json  \n",
            "  inflating: comet-atomic_2020_BART/.DS_Store  \n",
            "  inflating: __MACOSX/comet-atomic_2020_BART/._.DS_Store  \n",
            "  inflating: comet-atomic_2020_BART/tokenizer_config.json  \n",
            "  inflating: comet-atomic_2020_BART/special_tokens_map.json  \n",
            "  inflating: comet-atomic_2020_BART/config.json  \n",
            "  inflating: comet-atomic_2020_BART/.added_tokens.json.swp  \n",
            "  inflating: comet-atomic_2020_BART/merges.txt  \n",
            "  inflating: comet-atomic_2020_BART/pytorch_model.bin  \n",
            "  inflating: comet-atomic_2020_BART/vocab.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVAdEJxEknx5",
        "outputId": "c150ed13-8db5-4257-cd9c-714b6a580d87"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_root = \"/content/drive/MyDrive/ANLP21/\"\n",
        "output_dir = \"/content/drive/MyDrive/ANLP21/train_concats/\"\n",
        "output_file = data_root+'concatenated.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR7NkfQOkq8E",
        "outputId": "03a60b97-a1d1-4abe-c7d4-20184da914b1"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1,r'./comet-atomic-2020/models/comet_atomic2020_bart')\n",
        "from generation_example import Comet\n",
        "print(\"model loading ...\")\n",
        "comet = Comet(\"comet-atomic_2020_BART\")\n",
        "comet.model.zero_grad()\n",
        "print(\"model loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loading ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXEq6ScIetg7"
      },
      "source": [
        "import pandas as pd\n",
        "cf = pd.read_csv(data_root+'character_tour_manual_part1_split.csv')\n",
        "cf = cf[cf.apply(lambda row: row['dev_train_test'] in ['test' , 'train' ,'dev'], axis=1)]\n",
        "cf['film'] = cf['film'].apply(lambda film: film.replace(\".txt.txt.txt.txt.txt.txt.txt\",\".txt\"))\n",
        "cf_list = cf['film'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFqmFnWAO3Se"
      },
      "source": [
        "import os\n",
        "done_list = [file.replace(\".csv\", \"\") for file in os.listdir(output_dir)]\n",
        "\n",
        "def film_name_condition(film_name):\n",
        "  return film_name in cf_list and film_name not in done_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEXRJnJhNqu_"
      },
      "source": [
        "import string\n",
        "inference_backup = pd.read_csv('/content/drive/MyDrive/ANLP21/inference_backup.csv')\n",
        "\n",
        "backup_films = inference_backup['film'].to_list()\n",
        "backup_items = inference_backup['item'].to_list()\n",
        "\n",
        "def from_backup(film, item, relation):\n",
        "  if(film in backup_films) and (item in backup_items) and (relation in inference_backup.columns):\n",
        "    d = (inference_backup[inference_backup.apply(lambda row: (row['film']==film) and (row['item'] == item) and (row[relation]!=\"\"), axis=1)])\n",
        "    inferences =  d[relation].to_list()[0].strip('][').split(', ')\n",
        "    return [i.translate(str.maketrans('', '', string.punctuation)).strip() for i in inferences]\n",
        "  else:\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrsqf2RTlAAf"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(data_root+\"database.csv\")\n",
        "df = df[df.apply(lambda row: film_name_condition(row['film']) and pd.notnull(row['character']), axis=1 )]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0BdaGPFlPZLI",
        "outputId": "4949c990-61e6-458d-9904-d9966b0a01de"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>film</th>\n",
              "      <th>scene</th>\n",
              "      <th>item_ids</th>\n",
              "      <th>item</th>\n",
              "      <th>character</th>\n",
              "      <th>protagonist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>trainspotting.txt</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>RENTON (V.O.) says, \"Choose life. Choose a job...</td>\n",
              "      <td>RENTON (V.O.)</td>\n",
              "      <td>RENTON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>trainspotting.txt</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>RENTON (V.O.) says, \"Choose good health, low c...</td>\n",
              "      <td>RENTON (V.O.)</td>\n",
              "      <td>RENTON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>trainspotting.txt</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>RENTON (V.O.) says, \"Choose leisure wear and m...</td>\n",
              "      <td>RENTON (V.O.)</td>\n",
              "      <td>RENTON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>trainspotting.txt</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>RENTON (V.O.) says, \"I chose not to choose lif...</td>\n",
              "      <td>RENTON (V.O.)</td>\n",
              "      <td>RENTON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>trainspotting.txt</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>SICK BOY says, \"Goldfinger's better than Dr. N...</td>\n",
              "      <td>SICK BOY</td>\n",
              "      <td>RENTON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895272</th>\n",
              "      <td>895272</td>\n",
              "      <td>rko_281.txt</td>\n",
              "      <td>76</td>\n",
              "      <td>3</td>\n",
              "      <td>WELLES says, \"You know, all this nightmare we ...</td>\n",
              "      <td>WELLES</td>\n",
              "      <td>WELLES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895273</th>\n",
              "      <td>895273</td>\n",
              "      <td>rko_281.txt</td>\n",
              "      <td>76</td>\n",
              "      <td>4</td>\n",
              "      <td>MANK says, \"Yeah, you're probably right.\"</td>\n",
              "      <td>MANK</td>\n",
              "      <td>WELLES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895275</th>\n",
              "      <td>895275</td>\n",
              "      <td>rko_281.txt</td>\n",
              "      <td>76</td>\n",
              "      <td>6</td>\n",
              "      <td>MANK says, \"I'll tell ya something, kid. When ...</td>\n",
              "      <td>MANK</td>\n",
              "      <td>WELLES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895278</th>\n",
              "      <td>895278</td>\n",
              "      <td>rko_281.txt</td>\n",
              "      <td>76</td>\n",
              "      <td>9</td>\n",
              "      <td>WELLES says, \"Will burn. Burn up. Burn out.  B...</td>\n",
              "      <td>WELLES</td>\n",
              "      <td>WELLES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895280</th>\n",
              "      <td>895280</td>\n",
              "      <td>rko_281.txt</td>\n",
              "      <td>76</td>\n",
              "      <td>11</td>\n",
              "      <td>WELLES says, \"Cheers.\"</td>\n",
              "      <td>WELLES</td>\n",
              "      <td>WELLES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>95785 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0               film  ...      character  protagonist\n",
              "9                9  trainspotting.txt  ...  RENTON (V.O.)       RENTON\n",
              "15              15  trainspotting.txt  ...  RENTON (V.O.)       RENTON\n",
              "27              27  trainspotting.txt  ...  RENTON (V.O.)       RENTON\n",
              "33              33  trainspotting.txt  ...  RENTON (V.O.)       RENTON\n",
              "34              34  trainspotting.txt  ...       SICK BOY       RENTON\n",
              "...            ...                ...  ...            ...          ...\n",
              "895272      895272        rko_281.txt  ...         WELLES       WELLES\n",
              "895273      895273        rko_281.txt  ...           MANK       WELLES\n",
              "895275      895275        rko_281.txt  ...           MANK       WELLES\n",
              "895278      895278        rko_281.txt  ...         WELLES       WELLES\n",
              "895280      895280        rko_281.txt  ...         WELLES       WELLES\n",
              "\n",
              "[95785 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px_0huAfkvQ3"
      },
      "source": [
        "relations = [ \"xAttr\",  \"MotivatedByGoal\", \"xReact\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6I6m0Fjk8kf",
        "outputId": "ed79e30b-882b-4a01-f57d-6b0215f8fd8b"
      },
      "source": [
        "def infer(item):\n",
        "  # results = []\n",
        "  # comet_run_needed = False\n",
        "  # for relation in relations:\n",
        "  #   result = from_backup(film, item, relation)\n",
        "  #   if result is None:\n",
        "  #     comet_run_needed = True\n",
        "  #     break\n",
        "  #   else:\n",
        "  #     results.append(result)\n",
        "  # if(comet_run_needed):\n",
        "    results = []\n",
        "    queries= [\"{} {} [GEN]\".format(item, relation) for relation in relations]\n",
        "    results = comet.generate(queries, decode_method=\"beam\", num_generate=5)\n",
        "    \n",
        "    return results\n",
        "\n",
        "film_group = df.groupby('film')\n",
        "df_concat = []\n",
        "film_names = []\n",
        "for film, group in film_group:\n",
        "    print(film)\n",
        "    #The following three ways were quicker ways but they don't work for some reason\n",
        "    # if you want to work with these make sure to convert the results array in infer into json or string before returning\n",
        "    # group['inference'] = comet.generate([\"{} {} [GEN]\".format(group['item'], relation) for relation in relations], decode_method=\"beam\", num_generate=5)\n",
        "    # group['inference'] = group['item'].apply((lambda x: infer(x)), axis=1)\n",
        "    # group['inference'] = infer(group['item'])\n",
        "    # for i in range(len(relations)):\n",
        "    #   # group[str(relations[i])] = group['inference'].apply((lambda x: parse_inf(x, i)), axis=1)\n",
        "    #   group[str(relations[i])] = parse_inf(group['inference'], i)\n",
        "    for i in range(len(relations)):\n",
        "      group[relations[i]] = [\"\" for i in range(len(group))]\n",
        "\n",
        "    rel_inf = []\n",
        "    for ind in group.index:\n",
        "      item = group['item'][ind]\n",
        "      results = infer(item)\n",
        "      for i in range(len(relations)):\n",
        "        group[relations[i]][ind] = results[i]\n",
        "    \n",
        "    df_concat.append(group)\n",
        "    film_names.append(film)\n",
        "    group.to_csv(output_dir+film+'.csv')\n",
        "    # files.download(output_dir+film+'.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "its_a_wonderful_life.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jane_eyre.txt\n",
            "jaws.txt\n",
            "jay_and_silent_bob_strike_back.txt\n",
            "jerry_maguire.txt\n",
            "jfk.txt\n",
            "juno.txt\n",
            "jurassic_park.txt\n",
            "jurassic_park_2_the_lost_world.txt\n",
            "kafka.txt\n",
            "kids.txt\n",
            "klute.txt\n",
            "l.a._confidential.txt\n",
            "lethal_weapon.txt\n",
            "life_as_a_house.txt\n",
            "logans_run.txt\n",
            "love_and_basketball.txt\n",
            "major_league.txt\n",
            "mash.txt\n",
            "memento.txt\n",
            "men_in_black.txt\n",
            "midnight_cowboy.txt\n",
            "millers_crossing.txt\n",
            "minority_report.txt\n",
            "mission_impossible_ii.txt\n",
            "mr._smith_goes_to_washington.txt\n",
            "never_been_kissed.txt\n",
            "next_friday.txt\n",
            "officer_and_a_gentleman_an.txt\n",
            "on_the_waterfront.txt\n",
            "one_flew_over_the_cuckoos_nest.txt\n",
            "pet_sematary.txt\n",
            "pitch_black.txt\n",
            "platoon.txt\n",
            "pleasantville.txt\n",
            "psycho.txt\n",
            "pulp_fiction.txt\n",
            "punch_drunk_love.txt\n",
            "rebel_without_a_cause.txt\n",
            "reservoir_dogs.txt\n",
            "resident_evil__romero__unproduced.txt\n",
            "rko_281.txt\n",
            "rocky.txt\n",
            "rush_hour.txt\n",
            "rush_hour_2.txt\n",
            "saving_private_ryan.txt\n",
            "schindlers_list.txt\n",
            "serial_mom.txt\n",
            "sex_lies_and_videotape.txt\n",
            "shampoo.txt\n",
            "signs.txt\n",
            "sling_blade.txt\n",
            "smokey_and_the_bandit.txt\n",
            "some_like_it_hot.txt\n",
            "south_park_bigger_longer_uncut.txt\n",
            "star_trek_07_generations.txt\n",
            "star_trek_08_first_contact.txt\n",
            "star_trek_10_nemesis.txt\n",
            "swingers.txt\n",
            "taxi_driver.txt\n",
            "terminator.txt\n",
            "the_5th_element.txt\n",
            "the_abyss.txt\n",
            "the_anniversary_party.txt\n",
            "the_battle_of_shaker_heights.txt\n",
            "the_birds.txt\n",
            "the_bourne_identity.txt\n",
            "the_butterfly_effect.txt\n",
            "the_cell.txt\n",
            "the_cider_house_rules.txt\n",
            "the_cooler.txt\n",
            "the_doors.txt\n",
            "the_english_patient.txt\n",
            "the_fabulous_baker_boys.txt\n",
            "the_family_man.txt\n",
            "the_fantastic_four.txt\n",
            "the_fisher_king.txt\n",
            "the_game.txt\n",
            "the_godfather.txt\n",
            "the_godfather_part_2.txt\n",
            "the_graduate.txt\n",
            "the_hustler.txt\n",
            "the_insider.txt\n",
            "the_lost_boys.txt\n",
            "the_majestic.txt\n",
            "the_man_who_wasnt_there.txt\n",
            "the_mummy_1999.txt\n",
            "the_nightmare_before_christmas.txt\n",
            "the_pianist.txt\n",
            "the_princess_bride.txt\n",
            "the_salton_sea.txt\n",
            "the_searchers.txt\n",
            "the_shawshank_redemption.txt\n",
            "the_shining.txt\n",
            "the_shipping_news.txt\n",
            "the_sixth_sense.txt\n",
            "the_talented_mr._ripley.txt\n",
            "the_truman_show.txt\n",
            "thelma_and_louise.txt\n",
            "theres_something_about_mary.txt\n",
            "thirteen_days.txt\n",
            "thor_ragnarok.txt\n",
            "titanic.txt\n",
            "toy_story.txt\n",
            "traffic.txt\n",
            "trainspotting.txt\n",
            "unbreakable.txt\n",
            "unforgiven.txt\n",
            "wall_street.txt\n",
            "what_lies_beneath.txt\n",
            "who_framed_roger_rabbit_who_shot_roger_rabbit.txt\n",
            "wonder_boys.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOj-XWRtt9EJ"
      },
      "source": [
        "df = pd.concat([pd.read_csv(os.path.join(output_dir, _)) for _ in os.listdir(fileDir) if _.endswith(\".csv\")])\n",
        "df.to_csv(output_dir+'concatenated-all-characters.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csm_oABoxd4v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}