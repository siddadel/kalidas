{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dialogue-Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNY6IOPmH0jl96f3CU80zeP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddadel/kalidas/blob/main/Dialogue_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBa6UJ_Fnqeh",
        "outputId": "6e3d04e2-ed35-4881-f7dd-b86fa28ae511"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec  1 02:52:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0T14RFvnzu4",
        "outputId": "4eb9be42-2173-4388-dadc-ffd68be4c129"
      },
      "source": [
        "!pip install transformers --quiet\n",
        "!git clone https://github.com/allenai/comet-atomic-2020\n",
        "!pip install -r ./comet-atomic-2020/requirements.txt --quiet\n",
        "!wget https://storage.googleapis.com/ai2-mosaic-public/projects/mosaic-kgs/comet-atomic_2020_BART.zip\n",
        "!unzip comet-atomic_2020_BART.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 82.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 67.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 70.9 MB/s \n",
            "\u001b[?25hCloning into 'comet-atomic-2020'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 166 (delta 42), reused 84 (delta 27), pack-reused 56\u001b[K\n",
            "Receiving objects: 100% (166/166), 7.15 MiB | 20.75 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 313 kB 52.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 60.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 379 kB 89.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 75.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 81.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 84.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 73.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 69.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 95.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 791 kB 83.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 374 kB 68.5 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pympler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.23 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.5.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.30.0 which is incompatible.\u001b[0m\n",
            "--2021-12-01 02:52:49--  https://storage.googleapis.com/ai2-mosaic-public/projects/mosaic-kgs/comet-atomic_2020_BART.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 142.250.107.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1507095346 (1.4G) [application/zip]\n",
            "Saving to: ‘comet-atomic_2020_BART.zip’\n",
            "\n",
            "comet-atomic_2020_B 100%[===================>]   1.40G   143MB/s    in 9.6s    \n",
            "\n",
            "2021-12-01 02:52:59 (149 MB/s) - ‘comet-atomic_2020_BART.zip’ saved [1507095346/1507095346]\n",
            "\n",
            "Archive:  comet-atomic_2020_BART.zip\n",
            "   creating: comet-atomic_2020_BART/\n",
            "  inflating: comet-atomic_2020_BART/added_tokens.json  \n",
            "  inflating: comet-atomic_2020_BART/.DS_Store  \n",
            "  inflating: __MACOSX/comet-atomic_2020_BART/._.DS_Store  \n",
            "  inflating: comet-atomic_2020_BART/tokenizer_config.json  \n",
            "  inflating: comet-atomic_2020_BART/special_tokens_map.json  \n",
            "  inflating: comet-atomic_2020_BART/config.json  \n",
            "  inflating: comet-atomic_2020_BART/.added_tokens.json.swp  \n",
            "  inflating: comet-atomic_2020_BART/merges.txt  \n",
            "  inflating: comet-atomic_2020_BART/pytorch_model.bin  \n",
            "  inflating: comet-atomic_2020_BART/vocab.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH2O85T7n3kW",
        "outputId": "4d765828-43e5-42ec-8990-a759dbab87b0"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_root = \"/content/drive/MyDrive/ANLP21/scripts_txt\"\n",
        "#data_root = \"/content/drive/MyDrive/ANLP21/scripts_sample\"\n",
        "output_dir= \"/content/drive/MyDrive/ANLP21/exp\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdFAeg3MogFK"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from joblib import Parallel, delayed\n",
        "import pandas as pd\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1rJLiWlpiio",
        "outputId": "35043766-c8bb-46c7-c4ec-828625b19ed4"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1,r'./comet-atomic-2020/models/comet_atomic2020_bart')\n",
        "from generation_example import Comet\n",
        "print(\"model loading ...\")\n",
        "comet = Comet(\"comet-atomic_2020_BART\")\n",
        "comet.model.zero_grad()\n",
        "print(\"model loaded\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loading ...\n",
            "model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dW_Eb_QoO0W"
      },
      "source": [
        "relations = [\"CapableOf\",  \"Desires\",  \"MotivatedByGoal\",  \"xAttr\", \"xNeed\", \"xReact\", \"xReason\", \"xWant\"]\n",
        "\n",
        "vocabulary = set()\n",
        "\n",
        "film_bags = {}\n",
        "\n",
        "def register_in_bag(film, token, relation):\n",
        "    if film not in film_bags:\n",
        "      film_bags[film] = {}\n",
        "    if(relation not in film_bags[film]):\n",
        "      film_bags[film][relation] = set()\n",
        "    film_bags[film][relation].add(token)\n",
        "    vocabulary.add(token)\n",
        "    \n",
        "def process_results(film, results, relations):\n",
        "    for i in range(len(relations)):\n",
        "      relation = relations[i]\n",
        "      for result in results[i]:\n",
        "        tokens = result.split(' ')\n",
        "        for token in tokens:\n",
        "          if token not in nlp.Defaults.stop_words:\n",
        "            register_in_bag(film, token, relation)\n",
        "\n",
        "log = []\n",
        "def infer(film, item, relations):\n",
        "    queries= [\"{} {} [GEN]\".format(item, relation) for relation in relations]\n",
        "    results = comet.generate(queries, decode_method=\"beam\", num_generate=5)\n",
        "    if film not in log:\n",
        "      print(film, end=\",\")\n",
        "      log.append(film)\n",
        "    process_results(film, results, relations)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft6jzHstn8Wu"
      },
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/ANLP21/data.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UryZcbQcn8NZ"
      },
      "source": [
        "# df1.apply(lambda row: infer(row['film'], row['item'], relations), axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf9OnkWnoIxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d49907-e2ad-4e76-f53b-ca525e0570de"
      },
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def infer(item):\n",
        "  queries= [\"{} {} [GEN]\".format(item, relation) for relation in relations]\n",
        "  results = comet.generate(queries, decode_method=\"beam\", num_generate=5)\n",
        "  return results\n",
        "\n",
        "film_group = df1.groupby('film')\n",
        "df_concat = []\n",
        "film_names = []\n",
        "for film, group in film_group:\n",
        "  print(film)\n",
        "  #The following three ways were quicker ways but they don't work for some reason\n",
        "  # if you want to work with these make sure to convert the results array in infer into json or string before returning\n",
        "  # group['inference'] = comet.generate([\"{} {} [GEN]\".format(group['item'], relation) for relation in relations], decode_method=\"beam\", num_generate=5)\n",
        "  # group['inference'] = group['item'].apply((lambda x: infer(x)), axis=1)\n",
        "  # group['inference'] = infer(group['item'])\n",
        "  # for i in range(len(relations)):\n",
        "  #   # group[str(relations[i])] = group['inference'].apply((lambda x: parse_inf(x, i)), axis=1)\n",
        "  #   group[str(relations[i])] = parse_inf(group['inference'], i)\n",
        "  for i in range(len(relations)):\n",
        "    group[relations[i]] = [\"\" for i in range(len(group))]\n",
        "\n",
        "  rel_inf = []\n",
        "  for ind in group.index:\n",
        "    item = group['item'][ind]\n",
        "    results = infer(item)\n",
        "    for i in range(len(relations)):\n",
        "      group[relations[i]][ind] = results[i]\n",
        "  \n",
        "  df_concat.append(group)\n",
        "  film_names.append(film)\n",
        "  group.to_csv(film+'.csv')\n",
        "  files.download(film+'.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10_things_i_hate_about_you.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31OMT4nn9Jnl"
      },
      "source": [
        "df = pd.concat(df_concat)\n",
        "df.to_csv('concatenated.csv')\n",
        "files.download('concatenated.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Q6AbhU9Kmc"
      },
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm1WPSFLtvZi"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "def word_cloud(tokens, film_name, relation):\n",
        "  wordcloud = WordCloud(width = 800, height = 800,\n",
        "                  background_color ='white',\n",
        "                  stopwords = nlp.Defaults.stop_words,\n",
        "                  min_font_size = 10).generate(tokens)\n",
        "  \n",
        "  # plot the WordCloud image                      \n",
        "  plt.figure(figsize = (8, 8), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad = 0)\n",
        "  \n",
        "  plt.show()\n",
        "  plt.savefig(film_name+'_'+relation+'.png')\n",
        "  files.download(film_name+'_'+relation+'.png')\n",
        "\n",
        "for d in range(len(df_concat)):\n",
        "    group = df_concat[d]\n",
        "    film_name = film_names[d]\n",
        "    for i in range(len(relations)):\n",
        "      tokens = set()\n",
        "      for l in group[relations[i]]:\n",
        "        for word in list(l):\n",
        "          tokens.add(word)\n",
        "      tokens = str(tokens)\n",
        "      print(film_name, relations[i])\n",
        "      word_cloud(tokens, film_name, relations[i])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhINm51pzPUq"
      },
      "source": [
        "for d in range(len(df_concat)):\n",
        "  group = df_concat[d]\n",
        "  film_name = film_names[d]\n",
        "  for i in range(len(relations)):\n",
        "    files.download(film_name+'_'+relations[i]+'.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtlbuKa2FT77"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}